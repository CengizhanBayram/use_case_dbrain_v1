<img width="863" height="683" alt="image" src="https://github.com/user-attachments/assets/48a7f042-2b06-40f1-8311-61c0b44f404b" />

<img width="567" height="835" alt="image" src="https://github.com/user-attachments/assets/cb5dc676-5708-4a88-b1f8-6f7739512993" />

Aynen ÅŸimdi bu hale geldiÄŸine gÃ¶re READMEâ€™yi yazalÄ±m. AÅŸaÄŸÄ±yÄ± direkt `README.md` olarak kaydedebilirsin. âœ¨

---

````markdown
# Azure TÃ¼rkÃ§e Voice-based Q&A Agent (ASR + RAG + TTS)

Bu proje, **TÃ¼rkÃ§e haber transkriptlerinden** oluÅŸturulmuÅŸ bir bilgi tabanÄ± Ã¼zerinde Ã§alÄ±ÅŸan, uÃ§tan uca **ses tabanlÄ± soru-cevap (voice-based Q&A) ajanÄ±**dÄ±r.

Pipeline:

- ğŸ™ **ASR (Whisper, Azure OpenAI)**  
- ğŸ” **RAG (Gemini Embedding + FAISS VectorStore)**  
- ğŸ§  **LLM (Azure OpenAI Chat)**  
- ğŸ”Š **TTS (Azure OpenAI TTS)**  
- ğŸ’» **Web ArayÃ¼zÃ¼ (HTML + JS, FastAPI Ã¼zerinden servis ediliyor)**  

KullanÄ±cÄ± hem **metinle** hem de **sesli** olarak soru sorabilir, cevaplarÄ± hem ekranda gÃ¶rÃ¼r hem de **TÃ¼rkÃ§e seslendirilmiÅŸ** olarak dinleyebilir.

---

## 1. Mimari Genel BakÄ±ÅŸ

YÃ¼ksek seviye akÄ±ÅŸ:

1. **Knowledge Base (offline hazÄ±rlÄ±k)**  
   - OpenSLR 108 veri setindeki **TÃ¼rkÃ§e haber transkriptleri** alÄ±nÄ±r.  
   - Metinler parÃ§alara (chunk) bÃ¶lÃ¼nÃ¼r.  
   - Her parÃ§a, **Gemini `models/text-embedding-004`** ile vektÃ¶rize edilir.  
   - VektÃ¶rler **FAISS index** iÃ§inde saklanÄ±r, ham metinler `docs.pkl` olarak kaydedilir.

2. **Text Q&A (online)**  
   - KullanÄ±cÄ± TÃ¼rkÃ§e bir soruyu metin olarak girer.  
   - Soru, yine Gemini embedding modeliyle vektÃ¶rize edilir.  
   - FAISS Ã¼zerinden en alakalÄ± `top_k` haber parÃ§alarÄ± Ã§ekilir.  
   - Bu parÃ§alar ve soru, Azure OpenAI Chat deploymentâ€™Ä±na verilerek **TÃ¼rkÃ§e cevap** Ã¼retilir.  
   - Cevap ve kullanÄ±lan baÄŸlam parÃ§alarÄ± (contexts) frontendâ€™e dÃ¶ner.

3. **Voice Q&A (online)**  
   - KullanÄ±cÄ± mikrofonla soru sorar.  
   - TarayÄ±cÄ± ses kaydÄ±nÄ± backendâ€™e gÃ¶nderir (`/voice-qa`).  
   - Azure OpenAI Whisper deploymentâ€™Ä± ile **TÃ¼rkÃ§e transcript** Ã¼retilir.  
   - RAG pipeline (Embedding + FAISS + Chat) transcript Ã¼zerinden Ã§alÄ±ÅŸÄ±r.  
   - Azure OpenAI TTS deploymentâ€™Ä± ile TÃ¼rkÃ§e cevap **seslendirilir**.  
   - Frontend, hem cevabÄ± yazar hem de sesi otomatik Ã§almaya Ã§alÄ±ÅŸÄ±r.

---

## 2. Proje YapÄ±sÄ±

Ã–nemli dosya/klasÃ¶rler:

```text
Azure_Solution/
â”œâ”€ main.py               # FastAPI backend, RAG, ASR, TTS, API endpointleri
â”œâ”€ .env                  # Ortam deÄŸiÅŸkenleri (API keyler, deployment adlarÄ±, vb.)
â”œâ”€ frontend/
â”‚  â””â”€ index.html         # Modern chat arayÃ¼zÃ¼ (Metin + Ses modu)
â””â”€ vector_db/
   â”œâ”€ docs.pkl           # Haber parÃ§alarÄ±nÄ±n listesi (text)
   â”œâ”€ embeddings.npy     # Her parÃ§a iÃ§in embedding vektÃ¶rleri
   â””â”€ faiss_index.bin    # FAISS index
````

> Not: `vector_db` klasÃ¶rÃ¼ bu projede **Ã¶nceden oluÅŸturulmuÅŸ** kabul ediliyor. Embeddingâ€™ler, Gemini `models/text-embedding-004` ile Ã¼retilmiÅŸtir.

---

## 3. KullanÄ±lan Teknolojiler

* **Backend**

  * [FastAPI](https://fastapi.tiangolo.com/) â€“ HTTP API ve HTML servis
  * [Uvicorn](https://www.uvicorn.org/) â€“ ASGI server
  * [FAISS](https://github.com/facebookresearch/faiss) â€“ VektÃ¶r arama
  * `numpy`, `pickle`, `python-dotenv`

* **LLM / ASR / TTS**

  * **Azure OpenAI**

    * Chat: Ã¶rn. `gpt-4o-mini` deployment
    * Whisper: `whisper` deployment
    * TTS: `tts` deployment, voice: `alloy` (Azure OpenAI TTS)

* **Embedding**

  * **Google Gemini** â€“ `models/text-embedding-004` (via `google-generativeai`)

* **Frontend**

  * Vanilla HTML + CSS + JavaScript
  * Tek sayfa (SPA benzeri) chat UI, FastAPI root (`/`) Ã¼zerinden servis ediliyor.

---

## 4. Kurulum

### 4.1. Gereksinimler

* Python **3.10+**
* Pip
* Bir Azure OpenAI kaynaÄŸÄ±:

  * Chat deployment (Ã¶rnek: `gpt-4o-mini`)
  * Whisper ASR deployment (Ã¶rnek: `whisper`)
  * TTS deployment (Ã¶rnek: `tts`)
* Google Gemini API Key (embedding iÃ§in)

### 4.2. Sanal Ortam (opsiyonel ama tavsiye edilir)

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/macOS
source venv/bin/activate
```

### 4.3. Python Paketlerini Kur

```bash
pip install fastapi uvicorn
pip install openai
pip install google-generativeai
pip install python-dotenv
pip install faiss-cpu
pip install numpy
```

(eÄŸer gerekirse)

```bash
pip install pydantic
pip install "fastapi[all]"
```

> Projeye bir `requirements.txt` koymak istersen bu paketleri oraya ekleyebilirsin.

---

## 5. .env YapÄ±landÄ±rmasÄ±

Projenin kÃ¶k dizininde ( `main.py` ile aynÄ± klasÃ¶r) bir `.env` dosyasÄ± oluÅŸtur:

```env
# Azure OpenAI
AZURE_OPENAI_API_KEY=***
AZURE_OPENAI_ENDPOINT=https://<senin-resource-adÄ±n>.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-12-01-preview

# Deployment isimleri (Azure Portal > Deployments)
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_WHISPER_DEPLOYMENT=whisper
AZURE_OPENAI_TTS_DEPLOYMENT=tts

# TTS voice (Azure OpenAI TTS)
AZURE_OPENAI_TTS_VOICE=alloy

# Gemini
GEMINI_API_KEY=***

# Embedding modeli
EMBEDDING_MODEL_NAME=models/text-embedding-004

# Vector DB klasÃ¶rÃ¼
VECTOR_DIR=./vector_db

# RAG iÃ§in varsayÄ±lan top_k
TOP_K_DEFAULT=5
```

> Not: `AZURE_OPENAI_*_DEPLOYMENT` deÄŸerleri, kendi Azure OpenAI kaynaklarÄ±nda oluÅŸturduÄŸun **deployment adlarÄ±** olmalÄ±dÄ±r (model adlarÄ± deÄŸil, deployment name).

---

## 6. Vector DB (FAISS) HakkÄ±nda

Bu proje, `vector_db` klasÃ¶rÃ¼ndeki Ã¼Ã§ dosyanÄ±n **hazÄ±r olduÄŸunu** varsayar:

* `docs.pkl`:
  Python listesi (`List[str]`) â€“ her eleman, bir haber metni parÃ§asÄ± (chunk).
* `embeddings.npy`:
  `float32` matris (`num_docs x dim`) â€“ her satÄ±r bir dokÃ¼man embeddingâ€™i.
* `faiss_index.bin`:
  FAISS index dosyasÄ± â€“ `embeddings.npy` ile aynÄ± sÄ±rada ve boyutta.

Bu dosyalar, ayrÄ± bir preprocessing scriptâ€™i ile ÅŸu ÅŸekilde Ã¼retilmiÅŸtir:

1. OpenSLR 108 TÃ¼rkÃ§e haber veri setinden transkriptler okunur.
2. Metinler parÃ§alara bÃ¶lÃ¼nÃ¼r ve `docs` listesine alÄ±nÄ±r.
3. Her parÃ§a iÃ§in Gemini `models/text-embedding-004` ile embedding Ã¼retilir.
4. `embeddings.npy` kaydedilir.
5. FAISS index (`IndexFlatL2` vb.) oluÅŸturulur ve `faiss_index.bin` olarak kaydedilir.

> Ã–NEMLÄ°: Sorgu embeddingâ€™ini de **aynÄ± modelle** Ã¼rettiÄŸimiz iÃ§in (`models/text-embedding-004`), FAISS aramalarÄ± tutarlÄ± Ã§alÄ±ÅŸÄ±r.

---

## 7. UygulamayÄ± Ã‡alÄ±ÅŸtÄ±rma

### 7.1. Backendâ€™i baÅŸlat

Proje kÃ¶k dizininde:

```bash
python main.py
```

Logâ€™da ÅŸuna benzer bir ÅŸey gÃ¶rmelisin:

```text
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     Application startup complete.
```

### 7.2. Frontendâ€™e eriÅŸim

TarayÄ±cÄ±dan:

```text
http://127.0.0.1:8000
```

* `main.py` root (`/`) endpointâ€™inde `frontend/index.html` dosyasÄ±nÄ± dÃ¶ndÃ¼ÄŸÃ¼ iÃ§in, chat arayÃ¼zÃ¼ otomatik aÃ§Ä±lÄ±r.
* API Ã§aÄŸrÄ±larÄ± da aynÄ± origin Ã¼zerinden (Ã¶r. `http://127.0.0.1:8000/text-qa`) gider.

---

## 8. API Endpointleri

### 8.1. `GET /`

* `frontend/index.html` dosyasÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.
* Chat UIâ€™yi aÃ§mak iÃ§in kullanÄ±lÄ±r.

### 8.2. `GET /health`

Basit healthcheck endpointâ€™i:

```json
{
  "status": "ok"
}
```

### 8.3. `POST /text-qa`

**Input (JSON)**

```json
{
  "question": "TÃ¼rkiye ekonomisiyle ilgili haberlerde neler vurgulanÄ±yor?",
  "top_k": 5
}
```

* `question`: KullanÄ±cÄ±nÄ±n TÃ¼rkÃ§e sorusu.
* `top_k` (opsiyonel): FAISSâ€™ten kaÃ§ baÄŸlam parÃ§asÄ± alÄ±nacaÄŸÄ± (default: `.env`â€™deki `TOP_K_DEFAULT`).

**Output (JSON)**

```json
{
  "answer": "Cevap metni...",
  "contexts": [
    "Haber parÃ§asÄ± 1...",
    "Haber parÃ§asÄ± 2..."
  ]
}
```

* `answer`: Azure OpenAI Chat modeli tarafÄ±ndan Ã¼retilmiÅŸ cevap.
* `contexts`: Bu cevaba baÄŸlÄ± olarak kullanÄ±lan haber metni parÃ§alarÄ±.

### 8.4. `POST /voice-qa`

**Input (multipart/form-data)**

* `file`: TarayÄ±cÄ±dan kaydedilmiÅŸ `audio.wav` (tek kanal, PCM, vb.)

**Output (JSON)**

```json
{
  "transcript": "KullanÄ±cÄ±nÄ±n sÃ¶ylediÄŸi cÃ¼mlenin TÃ¼rkÃ§e transkripti",
  "answer": "Soruya verilen TÃ¼rkÃ§e cevap",
  "audio_base64": "<base64-encoded-wav>"
}
```

Frontend, `audio_base64` alanÄ±nÄ±:

* `data:audio/wav;base64,...` formatÄ±na Ã§evirerek
* Hem otomatik Ã§almaya Ã§alÄ±ÅŸÄ±r (`new Audio().play()`),
* Hem de mesaj balonu iÃ§inde `<audio controls>` player olarak gÃ¶sterir.

---

## 9. Demo Ä°Ã§in Notlar

GÃ¶rÃ¼ÅŸme/demoda gÃ¶sterebileceÄŸin akÄ±ÅŸ:

1. **Metin demo:**

   * ArayÃ¼zde â€œğŸ“ Metinâ€ modunu seÃ§.
   * Haber korpusu ile alakalÄ± bir soru yaz:

     * Ã–rn. â€œSon dÃ¶nemde enflasyon hakkÄ±ndaki haberler ne diyor?â€
   * CevabÄ±n altÄ±nda â€œğŸ“š Kaynak BaÄŸlamlarâ€ kÄ±smÄ±nda haber paragraflarÄ±nÄ± gÃ¶ster.

2. **Ses demo:**

   * â€œğŸ¤ Sesliâ€ moduna geÃ§.
   * Mikrofon butonuna bas, bir soru sor, tekrar basarak kaydÄ± bitir.
   * UI sÄ±rasÄ±yla:

     * Whisper transcriptâ€™ini yazÄ± olarak gÃ¶sterir,
     * Answerâ€™Ä± balonda gÃ¶sterip,
     * TTS ile Ã¼retilmiÅŸ sesi otomatik oynatÄ±r.

3. **Out-of-domain soru:**

   * Haber korpusu ile alakasÄ±z bir soru sor:

     * Ã–rn. â€œMarsâ€™ta yaÅŸam var mÄ±?â€
   * Backend, kelime kesiÅŸimi Ã§ok zayÄ±fsa:

     * `"Bu metin haber metinlerinde yok."` cevabÄ±nÄ± Ã¼retir,
     * BÃ¶ylece â€œhallucinationâ€ yerine net bir fallback davranÄ±ÅŸÄ± gÃ¶sterirsin.

---

## 10. KÄ±sÄ±tlar ve Ä°yileÅŸtirme Fikirleri

* Autoplay (otomatik ses Ã§alma) tarayÄ±cÄ±larÄ±n gÃ¼venlik politikalarÄ±na baÄŸlÄ±dÄ±r.
  Bu projede:

  * KullanÄ±cÄ± mikrofon butonuna tÄ±kladÄ±ÄŸÄ±nda hafif bir â€œaudio unlockâ€ tekniÄŸiyle izin tetiklenir.
  * BazÄ± tarayÄ±cÄ±larda yine de manuel play gerekebilir.
* Embedding ve FAISS index oluÅŸturma adÄ±mÄ± bu repoda gÃ¶sterilmemiÅŸtir;
  `vector_db` klasÃ¶rÃ¼ hazÄ±r varsayÄ±lmÄ±ÅŸtÄ±r.
* Whisper transcript kalitesi, mikrofona, konuÅŸma hÄ±zÄ±na ve gÃ¼rÃ¼ltÃ¼ye baÄŸlÄ±dÄ±r;
  gerekirse ASR tarafÄ±nda ek temizlik yapÄ±labilir.

---

Her ÅŸey bu kadar ğŸ§
Projeyi Ã§alÄ±ÅŸtÄ±rdÄ±ktan sonra tek yapman gereken `http://127.0.0.1:8000`â€™i aÃ§Ä±p metin veya sesli soru sormak.
Case sunumunda bu READMEâ€™yi de ekleyerek mimari ve tasarÄ±m kararlarÄ±nÄ± net bir ÅŸekilde anlatabilirsin.

```
::contentReference[oaicite:0]{index=0}
```
